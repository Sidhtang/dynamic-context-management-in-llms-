{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMryKDt7xTh/arluGkxp8AO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sidhtang/dynamic-context-management-in-llms-/blob/main/hierachical_text_qualification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSMo-ASQxyOm",
        "outputId": "795a0941-d46f-4eb9-8a56-f7d6dc3a3189"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "\n",
        "class HierarchicalChunker:\n",
        "    def __init__(self, model_name: str = \"sentence-transformers/all-mpnet-base-v2\"):\n",
        "        \"\"\"Initialize the hierarchical chunker with a specified embedding model.\"\"\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.levels = 3\n",
        "\n",
        "    def _get_embeddings(self, sentences: List[str]) -> np.ndarray:\n",
        "        \"\"\"Generate embeddings for a list of sentences.\"\"\"\n",
        "        encoded = self.tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**encoded)\n",
        "        return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "    def _extract_key_phrases(self, sentences: List[str], num_phrases: int = 5) -> List[str]:\n",
        "        \"\"\"Extract key phrases from sentences using word frequency.\"\"\"\n",
        "        words = []\n",
        "        for sentence in sentences:\n",
        "            words.extend([word.lower() for word in word_tokenize(sentence)\n",
        "                        if word.isalnum() and len(word) > 3])\n",
        "\n",
        "        word_freq = Counter(words)\n",
        "        return [word for word, _ in word_freq.most_common(num_phrases)]\n",
        "\n",
        "    def _create_level_summary(self, sentences: List[str], level: int) -> str:\n",
        "        \"\"\"Create a summary appropriate for the specified level.\"\"\"\n",
        "        if level == 1:\n",
        "            # Level 1: Single most representative sentence + key concepts\n",
        "            key_phrases = self._extract_key_phrases(sentences, 3)\n",
        "            embeddings = self._get_embeddings(sentences)\n",
        "            center = np.mean(embeddings, axis=0)\n",
        "            distances = np.linalg.norm(embeddings - center, axis=1)\n",
        "            main_sentence = sentences[np.argmin(distances)]\n",
        "            return f\"{main_sentence} Key concepts: {', '.join(key_phrases)}.\"\n",
        "\n",
        "        elif level == 2:\n",
        "            # Level 2: Topic-based summary using clustering\n",
        "            num_sentences = max(3, len(sentences) // 4)\n",
        "            embeddings = self._get_embeddings(sentences)\n",
        "            kmeans = KMeans(n_clusters=num_sentences, random_state=42)\n",
        "            clusters = kmeans.fit_predict(embeddings)\n",
        "\n",
        "            # Select most central sentence from each cluster\n",
        "            summary_sentences = []\n",
        "            for i in range(num_sentences):\n",
        "                cluster_mask = clusters == i\n",
        "                if np.any(cluster_mask):\n",
        "                    cluster_embeddings = embeddings[cluster_mask]\n",
        "                    cluster_center = kmeans.cluster_centers_[i]\n",
        "                    distances = np.linalg.norm(cluster_embeddings - cluster_center, axis=1)\n",
        "                    cluster_sentences = np.array(sentences)[cluster_mask]\n",
        "                    summary_sentences.append(cluster_sentences[np.argmin(distances)])\n",
        "\n",
        "            return \" \".join(summary_sentences)\n",
        "\n",
        "        else:\n",
        "            # Level 3: Detailed content organized by topics\n",
        "            return sentences\n",
        "\n",
        "    def chunk_text(self, text: str) -> Dict[str, Any]:\n",
        "        \"\"\"Break text into hierarchical chunks with different levels of abstraction.\"\"\"\n",
        "        sentences = sent_tokenize(text)\n",
        "\n",
        "        hierarchy = {\n",
        "            \"level_1\": self._create_level_summary(sentences, 1),\n",
        "            \"level_2\": self._create_level_summary(sentences, 2),\n",
        "            \"level_3\": sentences,\n",
        "            \"embeddings\": self._get_embeddings(sentences)\n",
        "        }\n",
        "\n",
        "        return hierarchy\n",
        "\n",
        "    def query_context(self, query: str, hierarchy: Dict[str, Any], level: int = None) -> str:\n",
        "        \"\"\"Query the hierarchical context at a specific level or automatically determine the best level.\"\"\"\n",
        "        query_embedding = self._get_embeddings([query])[0]\n",
        "\n",
        "        if level is None:\n",
        "            # Analyze query complexity and specificity\n",
        "            words = word_tokenize(query.lower())\n",
        "            question_words = set(['what', 'who', 'when', 'where', 'why', 'how'])\n",
        "            specificity_words = set(['specifically', 'detail', 'explain', 'describe', 'elaborate'])\n",
        "\n",
        "            if len(set(words) & question_words) == 1 and len(words) < 6:\n",
        "                level = 1  # Simple, single-concept queries\n",
        "            elif len(set(words) & specificity_words) > 0 or len(words) > 10:\n",
        "                level = 3  # Detailed queries\n",
        "            else:\n",
        "                level = 2  # Medium complexity queries\n",
        "\n",
        "        if level == 1:\n",
        "            return hierarchy[\"level_1\"]\n",
        "        elif level == 2:\n",
        "            return hierarchy[\"level_2\"]\n",
        "        else:\n",
        "            # Find most relevant detailed chunks and organize them\n",
        "            similarities = np.dot(hierarchy[\"embeddings\"], query_embedding)\n",
        "            top_indices = np.argsort(similarities)[-4:][::-1]  # Get top 4 most relevant chunks\n",
        "            relevant_chunks = [hierarchy[\"level_3\"][i] for i in top_indices]\n",
        "            return \" \".join(relevant_chunks)\n",
        "\n",
        "def demonstrate_chunking():\n",
        "    text = \"\"\"\n",
        "    Machine learning is a subset of artificial intelligence that focuses on developing systems that can learn from data.\n",
        "    These systems can identify patterns and make decisions with minimal human intervention.\n",
        "    The field has seen rapid growth in recent years due to increased data availability and computational power.\n",
        "    Deep learning, a subset of machine learning, uses neural networks with many layers to process complex patterns.\n",
        "    These neural networks are inspired by the human brain's structure and function.\n",
        "    They can be trained on large datasets to perform tasks like image recognition, natural language processing, and game playing.\n",
        "    The training process involves adjusting the network's parameters to minimize prediction errors.\n",
        "    Modern applications include autonomous vehicles, recommendation systems, and medical diagnosis tools.\n",
        "    Each application requires careful consideration of data quality, model architecture, and ethical implications.\n",
        "    The future of machine learning promises even more advanced applications and integration with other technologies.\n",
        "    \"\"\"\n",
        "\n",
        "    chunker = HierarchicalChunker()\n",
        "    hierarchy = chunker.chunk_text(text)\n",
        "\n",
        "    queries = {\n",
        "        \"simple\": \"What is machine learning?\",\n",
        "        \"medium\": \"How does deep learning relate to machine learning?\",\n",
        "        \"complex\": \"Explain the training process and applications of neural networks in detail.\"\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for query_type, query in queries.items():\n",
        "        results[query_type] = chunker.query_context(query, hierarchy)\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = demonstrate_chunking()\n",
        "    for query_type, response in results.items():\n",
        "        print(f\"\\n{query_type.upper()} QUERY RESPONSE:\")\n",
        "        print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGKjf_-wxMuZ",
        "outputId": "5f3cd8f9-d3cd-4f15-caed-99955f7b0301"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SIMPLE QUERY RESPONSE:\n",
            "Deep learning, a subset of machine learning, uses neural networks with many layers to process complex patterns. Key concepts: learning, machine, systems.\n",
            "\n",
            "MEDIUM QUERY RESPONSE:\n",
            "Deep learning, a subset of machine learning, uses neural networks with many layers to process complex patterns. Modern applications include autonomous vehicles, recommendation systems, and medical diagnosis tools. These systems can identify patterns and make decisions with minimal human intervention.\n",
            "\n",
            "COMPLEX QUERY RESPONSE:\n",
            "The training process involves adjusting the network's parameters to minimize prediction errors. Deep learning, a subset of machine learning, uses neural networks with many layers to process complex patterns. These neural networks are inspired by the human brain's structure and function. \n",
            "    Machine learning is a subset of artificial intelligence that focuses on developing systems that can learn from data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def demonstrate_improved_chunking():\n",
        "    # Sample text about machine learning and AI\n",
        "    text = \"\"\"\n",
        "    Artificial Intelligence (AI) represents the broad field of making machines intelligent.\n",
        "    Machine learning is a subset of AI that focuses on developing systems that can learn from data.\n",
        "    These systems automatically identify patterns and make decisions with minimal human intervention.\n",
        "    Deep learning is a specialized type of machine learning using neural networks with many layers.\n",
        "    Neural networks are computing systems inspired by biological brains and their interconnected neurons.\n",
        "    The training process involves feeding large amounts of data through these neural networks.\n",
        "    As data flows through the network, weights and biases are adjusted to minimize prediction errors.\n",
        "    Modern applications of deep learning include computer vision, natural language processing, and robotics.\n",
        "    Computer vision systems can recognize objects, faces, and even emotions in images and videos.\n",
        "    Natural language processing enables machines to understand and generate human language.\n",
        "    Robotics applications combine perception, planning, and control for autonomous behavior.\n",
        "    Ethical considerations in AI include privacy, bias, and the impact on employment.\n",
        "    Data quality and model transparency are crucial for building trustworthy AI systems.\n",
        "    The future of AI promises even more advanced applications across various industries.\n",
        "    \"\"\"\n",
        "\n",
        "    chunker = HierarchicalChunker()\n",
        "    hierarchy = chunker.chunk_text(text)\n",
        "\n",
        "    # Different types of queries to demonstrate level differentiation\n",
        "    queries = {\n",
        "        \"simple\": \"What is artificial intelligence?\",\n",
        "        \"medium\": \"How does deep learning work with neural networks?\",\n",
        "        \"complex\": \"Explain the applications and ethical considerations of deep learning in detail.\"\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    print(\"\\n=== DEMONSTRATION OF HIERARCHICAL RESPONSES ===\\n\")\n",
        "\n",
        "    for query_type, query in queries.items():\n",
        "        print(f\"\\n--- {query_type.upper()} QUERY: '{query}' ---\")\n",
        "\n",
        "        # Show responses at each level explicitly\n",
        "        for level in [1, 2, 3]:\n",
        "            response = chunker.query_context(query, hierarchy, level)\n",
        "            print(f\"\\nLEVEL {level} RESPONSE:\")\n",
        "            print(response)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demonstrate_improved_chunking()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znh-oDzuxMxW",
        "outputId": "fd76e827-99eb-42f6-c26d-7abc4081200b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DEMONSTRATION OF HIERARCHICAL RESPONSES ===\n",
            "\n",
            "\n",
            "--- SIMPLE QUERY: 'What is artificial intelligence?' ---\n",
            "\n",
            "LEVEL 1 RESPONSE:\n",
            "\n",
            "    Artificial Intelligence (AI) represents the broad field of making machines intelligent. Key concepts: systems, learning, data.\n",
            "\n",
            "LEVEL 2 RESPONSE:\n",
            "Neural networks are computing systems inspired by biological brains and their interconnected neurons. The future of AI promises even more advanced applications across various industries. Machine learning is a subset of AI that focuses on developing systems that can learn from data.\n",
            "\n",
            "LEVEL 3 RESPONSE:\n",
            "\n",
            "    Artificial Intelligence (AI) represents the broad field of making machines intelligent. Machine learning is a subset of AI that focuses on developing systems that can learn from data. Deep learning is a specialized type of machine learning using neural networks with many layers. Neural networks are computing systems inspired by biological brains and their interconnected neurons.\n",
            "\n",
            "==================================================\n",
            "\n",
            "--- MEDIUM QUERY: 'How does deep learning work with neural networks?' ---\n",
            "\n",
            "LEVEL 1 RESPONSE:\n",
            "\n",
            "    Artificial Intelligence (AI) represents the broad field of making machines intelligent. Key concepts: systems, learning, data.\n",
            "\n",
            "LEVEL 2 RESPONSE:\n",
            "Neural networks are computing systems inspired by biological brains and their interconnected neurons. The future of AI promises even more advanced applications across various industries. Machine learning is a subset of AI that focuses on developing systems that can learn from data.\n",
            "\n",
            "LEVEL 3 RESPONSE:\n",
            "Deep learning is a specialized type of machine learning using neural networks with many layers. The training process involves feeding large amounts of data through these neural networks. Neural networks are computing systems inspired by biological brains and their interconnected neurons. Modern applications of deep learning include computer vision, natural language processing, and robotics.\n",
            "\n",
            "==================================================\n",
            "\n",
            "--- COMPLEX QUERY: 'Explain the applications and ethical considerations of deep learning in detail.' ---\n",
            "\n",
            "LEVEL 1 RESPONSE:\n",
            "\n",
            "    Artificial Intelligence (AI) represents the broad field of making machines intelligent. Key concepts: systems, learning, data.\n",
            "\n",
            "LEVEL 2 RESPONSE:\n",
            "Neural networks are computing systems inspired by biological brains and their interconnected neurons. The future of AI promises even more advanced applications across various industries. Machine learning is a subset of AI that focuses on developing systems that can learn from data.\n",
            "\n",
            "LEVEL 3 RESPONSE:\n",
            "Ethical considerations in AI include privacy, bias, and the impact on employment. \n",
            "    Artificial Intelligence (AI) represents the broad field of making machines intelligent. Deep learning is a specialized type of machine learning using neural networks with many layers. Machine learning is a subset of AI that focuses on developing systems that can learn from data.\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ImxtjHlGxM0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Se03PLRxM3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2Z2XUgXxM6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZWSalWAxM-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1dioArNYxNBs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}